# Machine-Learning-A-Z-Udemy

 ## Introduce


 這門課程是Udemy的[Machine Learning A-Z-Hands-On Python & R in Data Science](https://www.udemy.com/machinelearningchinese/)。
   有Python與R的實作版本，在這我只會專注於R的部分。 
  
 
  1. 課程共有10個part，每一個part建立一個R代碼的檔案
  2. 練習中的DataSet可在此[下載](https://www.superdatascience.com/pages/%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86)
  
  
 這門課程是偏向實用的課程，有生動的實例實踐練習，但理論通常比較少，大約都只有高中程式的數學要求而己，
 所以大多章節都是用敍述方式解釋一下名詞，大概有個概念後，就開始用sklearn的工具，寫個三五行程式就完成了。 
 
總之這課程的感覺，熱鬧有餘，但是深度有點小小的不夠，code的量也不夠，但還是個很好的入門課程。
 如果有基本的理論基礎，上過吳恩達課程的話，這門課上起來應該是很得心應手，很容易有成就感。 
 
 
 ---------------------------------------

 This course is [Machine Learning A-Z-Hands-On Python & R in Data Science](https://www.udemy.com/machinelearningchinese/) on Udemy. 
 There are Python and R code, while here I will only focus on the R .

1. I will create an R code file for each part. 
2. All DataSet can be downloaded [here](https://www.superdatascience.com/pages/%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86)

This course is a practical course with vivid examples of practice, but the theory is usually less, 
only requires the high degree of mathematics. 
 Most chapters use narrative to explain nouns, and then use sklearn tools to write  few code. 
 

In short, I feel the depth and amount of code are not enough, but it is still a good introductory course. 
If you have a basic theoretical foundation, 
this class should be very handy and easy to have a sense of accomplishment.


## About this course
- Part 1 - Data Preprocessing
- Part 2 - Regression: Simple Linear Regression, Multiple Linear Regression, Polynomial Regression
- Part 3 - Classification: Logistic Regression, SVM, Kernel SVM, Naive Bayes, Decision Tree Classification, Random Forest Classification
- Part 4 - Clustering: K-Means
- Part 5 - Association Rule Learning: Apriori
- Part 6 - Reinforcement Learning: Upper Confidence Bound, Thompson Sampling
- Part 7 - Natural Language Processing: Bag-of-words model and algorithms for NLP
- Part 8 - Deep Learning: Artificial Neural Networks, Convolutional Neural Networks
- Part 9 - Dimensionality Reduction: PCA, Kernel PCA
- Part 10 - Model Selection & Boosting: k-fold Cross Validation, Grid Search.
 

